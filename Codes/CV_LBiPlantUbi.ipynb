{"cells":[{"cell_type":"markdown","metadata":{"id":"yBhqwecPfvM3"},"source":["Bộ dữ liệu chạy thử nghiệm là bộ dl lấy trong bài báo Improving protein succinylation sites prediction using embeddings from protein language model\n","link: https://www.nature.com/articles/s41598-022-21366-2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HOc-mgrK5B_6"},"outputs":[],"source":["import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import pickle as cPickle\n","\n","from sklearn.feature_selection import SelectFromModel\n","from sklearn.linear_model import Lasso, LogisticRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import roc_curve, auc\n","\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.layers import Bidirectional, LSTM, SimpleRNN, Input, GRU\n","from tensorflow.keras.layers import Dense, Activation, Dropout\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Flatten, Dense, Embedding, Dropout, Activation, MaxPooling1D,Conv1D\n","from tensorflow.keras.optimizers import SGD, Adam\n","from tensorflow.keras.layers import Dense, BatchNormalization, LeakyReLU\n","from tensorflow.keras.initializers import glorot_uniform\n","from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score,roc_auc_score\n","import sklearn.metrics as metrics\n","from keras import models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AQKbKXwNrah_","outputId":"5bb13e05-c414-4869-affa-de67687bdc10","executionInfo":{"status":"ok","timestamp":1720602585044,"user_tz":-420,"elapsed":26897,"user":{"displayName":"Xuân Trần","userId":"16348586452814696727"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OEYN-qcre5xb"},"outputs":[],"source":["path_train= \"/content/drive/MyDrive/LBiPlantUbi/Data/\"\n","path_test = \"/content/drive/MyDrive/LBiPlantUbi/Data/\"\n","path_result = \"/content/drive/MyDrive/LBiPlantUbi/Result/\"\n","path_model =\"/content/drive/MyDrive/LBiPlantUbi/Model/\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v4rNzH22PFrg"},"outputs":[],"source":["filename_train = \"trainset.csv\"\n","filename_test = \"testset.csv\"\n","file_train = filename_train\n","file_test = filename_test\n","df_train = pd.read_csv(path_train + file_train,  delimiter= ',')\n","df_test= pd.read_csv(path_test + filename_test,  delimiter= ',')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EPKGIOYCWmIk"},"outputs":[],"source":["# Def Dictionary\n","def  Dic_3_gram(): #Dictionary for 3_gram\n","    AA_list_sort = ['G','A','V','L','I','M','P','F','W','S','T','N','Q','Y','C','K','R','H','D','E','X']\n","\n","    AA_dict = {}\n","    numm = 1\n","    for i in AA_list_sort:\n","        for j in AA_list_sort:\n","          for jj in AA_list_sort:\n","             AA_dict[i+j+jj] = numm\n","             numm += 1\n","    return AA_dict\n","\n","def  Dic_2_gram():#Dictionary for 2_gram\n","    AA_list_sort = ['G','A','V','L','I','M','P','F','W','S','T','N','Q','Y','C','K','R','H','D','E','X']\n","\n","    AA_dict = {}\n","    numm = 1\n","    for i in AA_list_sort:\n","        for j in AA_list_sort:\n","          AA_dict[i+j] = numm\n","          numm += 1\n","    return AA_dict\n","\n","def Dic_1_gram():#Dictionary for 1_gram\n","    AA_list_sort = ['G','A','V','L','I','M','P','F','W','S','T','N','Q','Y','C','K','R','H','D','E','X']\n","\n","    AA_dict = {}\n","    numm = 1\n","    for i in AA_list_sort:\n","        AA_dict[i] = numm\n","        numm += 1\n","    return AA_dict\n","\n"]},{"cell_type":"code","source":["# Separate words in sentences\n","def ProSentence(pro, K):\n","\tsentence = \"\"\n","\tlength = len(pro)\n","\tfor i in range(length - K + 1):\n","\t\tsentence += pro[i: i + K] + \" \"\n","    #delete extra space\n","\tsentence = sentence[0 : len(sentence) - 1]\n","\treturn sentence\n","k =1#1-gram\n","word_index1 =  Dic_1_gram()\n","vocab_size = len(word_index1)"],"metadata":{"id":"1s_i3rSN6F88"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UtI2WXtnWmIk","outputId":"63ec0259-f17b-4c08-9b6b-bd970f0b3c61","executionInfo":{"status":"ok","timestamp":1720602715631,"user_tz":-420,"elapsed":907,"user":{"displayName":"Xuân Trần","userId":"16348586452814696727"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[['E', 'E', 'V', 'K', 'L', 'S', 'E', 'S', 'N', 'V', 'A', 'R', 'V', 'E', 'E', 'K', 'I', 'E', 'T', 'L', 'R', 'E', 'I', 'E', 'E', 'E', 'E', 'K', 'E', 'K', 'E'], ['E', 'G', 'M', 'H', 'P', 'R', 'V', 'L', 'V', 'D', 'G', 'F', 'E', 'I', 'A', 'K', 'R', 'A', 'T', 'L', 'Q', 'F', 'L', 'D', 'N', 'F', 'K', 'T', 'P', 'V', 'V']]\n"]}],"source":["# preprocessing test data and index number vector\n","texts_train =[]\n","for i in df_train['Sequence']:\n","  temp = ProSentence(i,k)\n","  texts_train.append(temp)\n","df_train['k_mer'] =texts_train\n","train_sequences = []\n","for each in texts_train:\n","    each_index_list = []\n","    each = each.split(' ')\n","    for i in each:\n","        each_index_list.append(word_index1[i])\n","    train_sequences.append(each_index_list)\n","\n","data_token = []\n","for i in df_train['k_mer']:\n","   data_token.append(i.split())\n","print(data_token[:2])\n","MAX_SEQUENCE_LENGTH = len(data_token[1])\n","\n","Xtrain = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n","ytrain = df_train['Label']\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3vEQrbdl2mYr","outputId":"8c21a268-0b17-4998-d533-1225359032f4","executionInfo":{"status":"ok","timestamp":1720602719644,"user_tz":-420,"elapsed":668,"user":{"displayName":"Xuân Trần","userId":"16348586452814696727"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([20, 20,  3, 16,  4, 10, 20, 10, 12,  3,  2, 17,  3, 20, 20, 16,  5,\n","       20, 11,  4, 17, 20,  5, 20, 20, 20, 20, 16, 20, 16, 20],\n","      dtype=int32)"]},"metadata":{},"execution_count":15}],"source":["Xtrain[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e0MigcD96Pkl"},"outputs":[],"source":["# preprocessing test data and index number vector\n","text_test =[] #PTMsequend kmer\n","for i in df_test['Sequence']:\n","  temp = ProSentence(i,k) #\n","  text_test.append(temp)\n","df_test['k_mer'] =text_test\n","test_sequences = []\n","for each in text_test:\n","    each_index_list = []\n","    each = each.split(' ')\n","    for i in each:\n","        each_index_list.append(word_index1[i])\n","    test_sequences.append(each_index_list)\n","\n","Xtest = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n","ytest= df_test['Label']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LpokFpv9d3fX"},"outputs":[],"source":["lr = 0.0001\n","num_epochs = 50\n","TIME_STEPS = MAX_SEQUENCE_LENGTH\n","INPUT_SIZE = 128 # The number of dimensions of the feature"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QdC9MeJOFzvs"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","from sklearn.model_selection import KFold\n","from keras.models import Sequential\n","from keras.layers import Conv1D, MaxPool1D, Flatten, Dense,GlobalAveragePooling1D\n","\n","from keras.layers import concatenate\n","from tensorflow.keras import Model\n","from keras.layers import Dense,Embedding,LSTM,Dropout,Bidirectional,GRU, Flatten\n","def Classifier_hybrid(): # define classification combine LSTM_BILSTM\n","    model1 = Sequential()\n","    model1.add(Embedding(vocab_size+1, INPUT_SIZE, input_length=MAX_SEQUENCE_LENGTH,trainable=True))\n","    model1.add(Dropout(0.5))\n","    model1.add(LSTM(units=64,batch_input_shape=(TIME_STEPS, INPUT_SIZE),return_sequences=True))\n","    model1.add(LSTM(units=64,batch_input_shape=(TIME_STEPS, INPUT_SIZE),return_sequences=True))\n","    model1.add(Flatten())\n","\n","\n","    model2 = Sequential()\n","\n","    model2.add(Embedding(vocab_size+1, INPUT_SIZE, input_length=MAX_SEQUENCE_LENGTH,trainable=True))\n","    model2.add(Dropout(0.5))\n","    model2.add(Bidirectional(LSTM(units=32,batch_input_shape=(TIME_STEPS, INPUT_SIZE),return_sequences=True)))\n","    model2.add(Flatten())\n","\n","    merged = concatenate(([model1.output, model2.output]))\n","    z = Dense(128, activation=\"relu\")(merged)\n","    z = Dropout(0.5)(z)\n","\n","    z = Dense(1, activation=\"sigmoid\")(z)\n","\n","    model = Model(inputs=[model1.input, model2.input], outputs=z)\n","\n","    model.compile(optimizer=keras.optimizers.Adam(learning_rate = lr),\n","                loss='binary_crossentropy',\n","                metrics=['accuracy',\"AUC\"])\n","\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XQYp_Boea8AF","outputId":"f6252e87-e175-4da5-ab1e-34c18114ff71","executionInfo":{"status":"ok","timestamp":1720602799247,"user_tz":-420,"elapsed":1251,"user":{"displayName":"Xuân Trần","userId":"16348586452814696727"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," embedding_input (InputLaye  [(None, 31)]                 0         []                            \n"," r)                                                                                               \n","                                                                                                  \n"," embedding (Embedding)       (None, 31, 128)              2816      ['embedding_input[0][0]']     \n","                                                                                                  \n"," embedding_1_input (InputLa  [(None, 31)]                 0         []                            \n"," yer)                                                                                             \n","                                                                                                  \n"," dropout (Dropout)           (None, 31, 128)              0         ['embedding[0][0]']           \n","                                                                                                  \n"," embedding_1 (Embedding)     (None, 31, 128)              2816      ['embedding_1_input[0][0]']   \n","                                                                                                  \n"," lstm (LSTM)                 (None, 31, 64)               49408     ['dropout[0][0]']             \n","                                                                                                  \n"," dropout_1 (Dropout)         (None, 31, 128)              0         ['embedding_1[0][0]']         \n","                                                                                                  \n"," lstm_1 (LSTM)               (None, 31, 64)               33024     ['lstm[0][0]']                \n","                                                                                                  \n"," bidirectional (Bidirection  (None, 31, 64)               41216     ['dropout_1[0][0]']           \n"," al)                                                                                              \n","                                                                                                  \n"," flatten (Flatten)           (None, 1984)                 0         ['lstm_1[0][0]']              \n","                                                                                                  \n"," flatten_1 (Flatten)         (None, 1984)                 0         ['bidirectional[0][0]']       \n","                                                                                                  \n"," concatenate (Concatenate)   (None, 3968)                 0         ['flatten[0][0]',             \n","                                                                     'flatten_1[0][0]']           \n","                                                                                                  \n"," dense (Dense)               (None, 128)                  508032    ['concatenate[0][0]']         \n","                                                                                                  \n"," dropout_2 (Dropout)         (None, 128)                  0         ['dense[0][0]']               \n","                                                                                                  \n"," dense_1 (Dense)             (None, 1)                    129       ['dropout_2[0][0]']           \n","                                                                                                  \n","==================================================================================================\n","Total params: 637441 (2.43 MB)\n","Trainable params: 637441 (2.43 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n"]}],"source":["model = Classifier_hybrid()\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LKulqSZ6KKBj"},"outputs":[],"source":["result_hybrid = path_result + \"Result_LBiPlantUbi.txt\""]},{"cell_type":"markdown","metadata":{"id":"YSWpmkAcKv-3"},"source":["Test Hybrid model CNN_BiLSM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8REUjI-s1R1H","colab":{"base_uri":"https://localhost:8080/"},"outputId":"130ddfcc-faa6-4906-a050-0cdb099315a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","310/310 [==============================] - 20s 34ms/step - loss: 0.6377 - accuracy: 0.6566 - auc: 0.7089\n","Epoch 2/50\n","310/310 [==============================] - 11s 34ms/step - loss: 0.5724 - accuracy: 0.7149 - auc: 0.7756\n","Epoch 3/50\n","310/310 [==============================] - 10s 34ms/step - loss: 0.5661 - accuracy: 0.7214 - auc: 0.7813\n","Epoch 4/50\n","310/310 [==============================] - 10s 34ms/step - loss: 0.5575 - accuracy: 0.7305 - auc: 0.7895\n","Epoch 5/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5460 - accuracy: 0.7354 - auc: 0.8003\n","Epoch 6/50\n","310/310 [==============================] - 11s 34ms/step - loss: 0.5402 - accuracy: 0.7360 - auc: 0.8052\n","Epoch 7/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5290 - accuracy: 0.7469 - auc: 0.8149\n","Epoch 8/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5260 - accuracy: 0.7438 - auc: 0.8172\n","Epoch 9/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5131 - accuracy: 0.7574 - auc: 0.8274\n","Epoch 10/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5063 - accuracy: 0.7582 - auc: 0.8316\n","Epoch 11/50\n","310/310 [==============================] - 10s 34ms/step - loss: 0.4917 - accuracy: 0.7673 - auc: 0.8424\n","Epoch 12/50\n","310/310 [==============================] - 11s 34ms/step - loss: 0.4880 - accuracy: 0.7705 - auc: 0.8465\n","Epoch 13/50\n","310/310 [==============================] - 10s 34ms/step - loss: 0.4770 - accuracy: 0.7760 - auc: 0.8540\n","Epoch 14/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4724 - accuracy: 0.7851 - auc: 0.8569\n","Epoch 15/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4655 - accuracy: 0.7828 - auc: 0.8613\n","Epoch 16/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4643 - accuracy: 0.7889 - auc: 0.8620\n","Epoch 17/50\n","310/310 [==============================] - 10s 34ms/step - loss: 0.4567 - accuracy: 0.7899 - auc: 0.8667\n","Epoch 18/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4516 - accuracy: 0.7909 - auc: 0.8702\n","Epoch 19/50\n","310/310 [==============================] - 10s 34ms/step - loss: 0.4456 - accuracy: 0.8008 - auc: 0.8747\n","Epoch 20/50\n","310/310 [==============================] - 11s 34ms/step - loss: 0.4469 - accuracy: 0.7964 - auc: 0.8735\n","Epoch 21/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4429 - accuracy: 0.8018 - auc: 0.8762\n","Epoch 22/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4411 - accuracy: 0.7966 - auc: 0.8769\n","Epoch 23/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4300 - accuracy: 0.8075 - auc: 0.8835\n","Epoch 24/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4285 - accuracy: 0.8117 - auc: 0.8854\n","Epoch 25/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4236 - accuracy: 0.8115 - auc: 0.8867\n","Epoch 26/50\n","310/310 [==============================] - 10s 34ms/step - loss: 0.4193 - accuracy: 0.8149 - auc: 0.8912\n","Epoch 27/50\n","310/310 [==============================] - 10s 34ms/step - loss: 0.4169 - accuracy: 0.8149 - auc: 0.8912\n","Epoch 28/50\n","310/310 [==============================] - 11s 34ms/step - loss: 0.4146 - accuracy: 0.8147 - auc: 0.8918\n","Epoch 29/50\n","310/310 [==============================] - 11s 35ms/step - loss: 0.4140 - accuracy: 0.8145 - auc: 0.8932\n","Epoch 30/50\n","310/310 [==============================] - 11s 34ms/step - loss: 0.4141 - accuracy: 0.8158 - auc: 0.8930\n","Epoch 31/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4013 - accuracy: 0.8232 - auc: 0.8996\n","Epoch 32/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4042 - accuracy: 0.8198 - auc: 0.8984\n","Epoch 33/50\n","310/310 [==============================] - 10s 34ms/step - loss: 0.4013 - accuracy: 0.8277 - auc: 0.8993\n","Epoch 34/50\n","310/310 [==============================] - 11s 34ms/step - loss: 0.3888 - accuracy: 0.8305 - auc: 0.9066\n","Epoch 35/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3865 - accuracy: 0.8321 - auc: 0.9078\n","Epoch 36/50\n","310/310 [==============================] - 10s 34ms/step - loss: 0.3871 - accuracy: 0.8311 - auc: 0.9070\n","Epoch 37/50\n","310/310 [==============================] - 10s 34ms/step - loss: 0.3853 - accuracy: 0.8323 - auc: 0.9076\n","Epoch 38/50\n","310/310 [==============================] - 10s 34ms/step - loss: 0.3787 - accuracy: 0.8354 - auc: 0.9120\n","Epoch 39/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3808 - accuracy: 0.8343 - auc: 0.9105\n","Epoch 40/50\n","310/310 [==============================] - 11s 34ms/step - loss: 0.3732 - accuracy: 0.8384 - auc: 0.9144\n","Epoch 41/50\n","310/310 [==============================] - 11s 34ms/step - loss: 0.3706 - accuracy: 0.8374 - auc: 0.9159\n","Epoch 42/50\n","310/310 [==============================] - 10s 34ms/step - loss: 0.3714 - accuracy: 0.8422 - auc: 0.9145\n","Epoch 43/50\n","310/310 [==============================] - 11s 34ms/step - loss: 0.3665 - accuracy: 0.8412 - auc: 0.9174\n","Epoch 44/50\n","310/310 [==============================] - 10s 34ms/step - loss: 0.3602 - accuracy: 0.8446 - auc: 0.9201\n","Epoch 45/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3617 - accuracy: 0.8384 - auc: 0.9189\n","Epoch 46/50\n","310/310 [==============================] - 11s 34ms/step - loss: 0.3607 - accuracy: 0.8461 - auc: 0.9201\n","Epoch 47/50\n","310/310 [==============================] - 11s 34ms/step - loss: 0.3490 - accuracy: 0.8489 - auc: 0.9256\n","Epoch 48/50\n","310/310 [==============================] - 11s 34ms/step - loss: 0.3493 - accuracy: 0.8535 - auc: 0.9255\n","Epoch 49/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3433 - accuracy: 0.8493 - auc: 0.9280\n","Epoch 50/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3355 - accuracy: 0.8596 - auc: 0.9317\n","18/18 [==============================] - 2s 15ms/step - loss: 0.4282 - accuracy: 0.8182 - auc: 0.8905\n","18/18 [==============================] - 2s 14ms/step\n","0.8181818181818182 0.6376300970730385 0.8455882352941176 0.7913669064748201\n","[[220  58]\n"," [ 42 230]]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-72-07de00e87821>:31: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  y_pred = [int(i) for i in y_pred]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","310/310 [==============================] - 19s 33ms/step - loss: 0.6372 - accuracy: 0.6503 - auc: 0.7027\n","Epoch 2/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5783 - accuracy: 0.7113 - auc: 0.7691\n","Epoch 3/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5682 - accuracy: 0.7236 - auc: 0.7791\n","Epoch 4/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5617 - accuracy: 0.7230 - auc: 0.7853\n","Epoch 5/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5549 - accuracy: 0.7301 - auc: 0.7919\n","Epoch 6/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5433 - accuracy: 0.7370 - auc: 0.8021\n","Epoch 7/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5372 - accuracy: 0.7426 - auc: 0.8083\n","Epoch 8/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5295 - accuracy: 0.7471 - auc: 0.8137\n","Epoch 9/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5216 - accuracy: 0.7570 - auc: 0.8208\n","Epoch 10/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5105 - accuracy: 0.7578 - auc: 0.8291\n","Epoch 11/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4959 - accuracy: 0.7681 - auc: 0.8408\n","Epoch 12/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4920 - accuracy: 0.7715 - auc: 0.8430\n","Epoch 13/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4856 - accuracy: 0.7739 - auc: 0.8474\n","Epoch 14/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4744 - accuracy: 0.7747 - auc: 0.8560\n","Epoch 15/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4740 - accuracy: 0.7788 - auc: 0.8555\n","Epoch 16/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4658 - accuracy: 0.7832 - auc: 0.8608\n","Epoch 17/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4617 - accuracy: 0.7822 - auc: 0.8646\n","Epoch 18/50\n","310/310 [==============================] - 11s 34ms/step - loss: 0.4570 - accuracy: 0.7895 - auc: 0.8674\n","Epoch 19/50\n","310/310 [==============================] - 10s 34ms/step - loss: 0.4604 - accuracy: 0.7889 - auc: 0.8658\n","Epoch 20/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4509 - accuracy: 0.7962 - auc: 0.8721\n","Epoch 21/50\n","310/310 [==============================] - 11s 35ms/step - loss: 0.4474 - accuracy: 0.7933 - auc: 0.8746\n","Epoch 22/50\n","310/310 [==============================] - 11s 34ms/step - loss: 0.4436 - accuracy: 0.7996 - auc: 0.8764\n","Epoch 23/50\n","310/310 [==============================] - 10s 34ms/step - loss: 0.4396 - accuracy: 0.7960 - auc: 0.8781\n","Epoch 24/50\n","310/310 [==============================] - 10s 34ms/step - loss: 0.4368 - accuracy: 0.7974 - auc: 0.8804\n","Epoch 25/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4334 - accuracy: 0.8077 - auc: 0.8833\n","Epoch 26/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4312 - accuracy: 0.8071 - auc: 0.8837\n","Epoch 27/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4250 - accuracy: 0.8093 - auc: 0.8871\n","Epoch 28/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4250 - accuracy: 0.8069 - auc: 0.8871\n","Epoch 29/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4206 - accuracy: 0.8137 - auc: 0.8902\n","Epoch 30/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4171 - accuracy: 0.8180 - auc: 0.8916\n","Epoch 31/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4123 - accuracy: 0.8149 - auc: 0.8942\n","Epoch 32/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4113 - accuracy: 0.8204 - auc: 0.8954\n","Epoch 33/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3996 - accuracy: 0.8188 - auc: 0.9006\n","Epoch 34/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3978 - accuracy: 0.8257 - auc: 0.9021\n","Epoch 35/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3903 - accuracy: 0.8265 - auc: 0.9061\n","Epoch 36/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3913 - accuracy: 0.8244 - auc: 0.9050\n","Epoch 37/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3956 - accuracy: 0.8255 - auc: 0.9036\n","Epoch 38/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3830 - accuracy: 0.8331 - auc: 0.9090\n","Epoch 39/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3884 - accuracy: 0.8315 - auc: 0.9069\n","Epoch 40/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3795 - accuracy: 0.8360 - auc: 0.9122\n","Epoch 41/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3783 - accuracy: 0.8275 - auc: 0.9108\n","Epoch 42/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3766 - accuracy: 0.8352 - auc: 0.9134\n","Epoch 43/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3656 - accuracy: 0.8438 - auc: 0.9183\n","Epoch 44/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3609 - accuracy: 0.8432 - auc: 0.9203\n","Epoch 45/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3660 - accuracy: 0.8384 - auc: 0.9178\n","Epoch 46/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3569 - accuracy: 0.8444 - auc: 0.9224\n","Epoch 47/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3542 - accuracy: 0.8499 - auc: 0.9233\n","Epoch 48/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3500 - accuracy: 0.8529 - auc: 0.9253\n","Epoch 49/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3446 - accuracy: 0.8509 - auc: 0.9273\n","Epoch 50/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3380 - accuracy: 0.8556 - auc: 0.9304\n","18/18 [==============================] - 2s 14ms/step - loss: 0.4393 - accuracy: 0.8218 - auc: 0.8798\n","18/18 [==============================] - 2s 14ms/step\n","0.8218181818181818 0.6442500245168047 0.8 0.8436363636363636\n","[[232  43]\n"," [ 55 220]]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-72-07de00e87821>:31: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  y_pred = [int(i) for i in y_pred]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","310/310 [==============================] - 17s 32ms/step - loss: 0.6333 - accuracy: 0.6570 - auc: 0.7080\n","Epoch 2/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5711 - accuracy: 0.7222 - auc: 0.7768\n","Epoch 3/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5612 - accuracy: 0.7220 - auc: 0.7866\n","Epoch 4/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5547 - accuracy: 0.7321 - auc: 0.7929\n","Epoch 5/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5499 - accuracy: 0.7293 - auc: 0.7969\n","Epoch 6/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5435 - accuracy: 0.7396 - auc: 0.8026\n","Epoch 7/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5375 - accuracy: 0.7347 - auc: 0.8070\n","Epoch 8/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5283 - accuracy: 0.7451 - auc: 0.8148\n","Epoch 9/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5163 - accuracy: 0.7509 - auc: 0.8245\n","Epoch 10/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5094 - accuracy: 0.7562 - auc: 0.8306\n","Epoch 11/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4995 - accuracy: 0.7636 - auc: 0.8371\n","Epoch 12/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4942 - accuracy: 0.7659 - auc: 0.8406\n","Epoch 13/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4858 - accuracy: 0.7745 - auc: 0.8473\n","Epoch 14/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4797 - accuracy: 0.7792 - auc: 0.8514\n","Epoch 15/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4715 - accuracy: 0.7812 - auc: 0.8571\n","Epoch 16/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4600 - accuracy: 0.7881 - auc: 0.8653\n","Epoch 17/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4598 - accuracy: 0.7925 - auc: 0.8654\n","Epoch 18/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4512 - accuracy: 0.7931 - auc: 0.8705\n","Epoch 19/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4493 - accuracy: 0.7990 - auc: 0.8722\n","Epoch 20/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4434 - accuracy: 0.7992 - auc: 0.8756\n","Epoch 21/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4412 - accuracy: 0.8034 - auc: 0.8767\n","Epoch 22/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4294 - accuracy: 0.8051 - auc: 0.8837\n","Epoch 23/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4269 - accuracy: 0.8073 - auc: 0.8856\n","Epoch 24/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4264 - accuracy: 0.8121 - auc: 0.8861\n","Epoch 25/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4258 - accuracy: 0.8069 - auc: 0.8860\n","Epoch 26/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4161 - accuracy: 0.8139 - auc: 0.8916\n","Epoch 27/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4217 - accuracy: 0.8109 - auc: 0.8881\n","Epoch 28/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4163 - accuracy: 0.8133 - auc: 0.8912\n","Epoch 29/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4096 - accuracy: 0.8172 - auc: 0.8949\n","Epoch 30/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4093 - accuracy: 0.8204 - auc: 0.8959\n","Epoch 31/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4045 - accuracy: 0.8192 - auc: 0.8979\n","Epoch 32/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3978 - accuracy: 0.8206 - auc: 0.9012\n","Epoch 33/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3996 - accuracy: 0.8265 - auc: 0.9007\n","Epoch 34/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3954 - accuracy: 0.8234 - auc: 0.9024\n","Epoch 35/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3943 - accuracy: 0.8275 - auc: 0.9039\n","Epoch 36/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3856 - accuracy: 0.8335 - auc: 0.9080\n","Epoch 37/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3812 - accuracy: 0.8402 - auc: 0.9112\n","Epoch 38/50\n","310/310 [==============================] - 10s 34ms/step - loss: 0.3798 - accuracy: 0.8352 - auc: 0.9107\n","Epoch 39/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3773 - accuracy: 0.8368 - auc: 0.9118\n","Epoch 40/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3719 - accuracy: 0.8368 - auc: 0.9144\n","Epoch 41/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3686 - accuracy: 0.8448 - auc: 0.9172\n","Epoch 42/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3671 - accuracy: 0.8420 - auc: 0.9174\n","Epoch 43/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3654 - accuracy: 0.8457 - auc: 0.9180\n","Epoch 44/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3586 - accuracy: 0.8469 - auc: 0.9219\n","Epoch 45/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3529 - accuracy: 0.8459 - auc: 0.9236\n","Epoch 46/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3570 - accuracy: 0.8448 - auc: 0.9216\n","Epoch 47/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3506 - accuracy: 0.8497 - auc: 0.9250\n","Epoch 48/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3446 - accuracy: 0.8505 - auc: 0.9277\n","Epoch 49/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3473 - accuracy: 0.8501 - auc: 0.9262\n","Epoch 50/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3415 - accuracy: 0.8531 - auc: 0.9292\n","18/18 [==============================] - 2s 14ms/step - loss: 0.5156 - accuracy: 0.7727 - auc: 0.8488\n","18/18 [==============================] - 2s 14ms/step\n","0.7727272727272727 0.5375501600250863 0.7131147540983607 0.8202614379084967\n","[[251  55]\n"," [ 70 174]]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-72-07de00e87821>:31: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  y_pred = [int(i) for i in y_pred]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","310/310 [==============================] - 19s 32ms/step - loss: 0.6330 - accuracy: 0.6513 - auc: 0.7041\n","Epoch 2/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5739 - accuracy: 0.7071 - auc: 0.7723\n","Epoch 3/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5627 - accuracy: 0.7244 - auc: 0.7855\n","Epoch 4/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5522 - accuracy: 0.7279 - auc: 0.7947\n","Epoch 5/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5446 - accuracy: 0.7307 - auc: 0.8018\n","Epoch 6/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5368 - accuracy: 0.7428 - auc: 0.8090\n","Epoch 7/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5270 - accuracy: 0.7481 - auc: 0.8173\n","Epoch 8/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5187 - accuracy: 0.7499 - auc: 0.8241\n","Epoch 9/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5070 - accuracy: 0.7543 - auc: 0.8332\n","Epoch 10/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5019 - accuracy: 0.7622 - auc: 0.8365\n","Epoch 11/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4937 - accuracy: 0.7642 - auc: 0.8420\n","Epoch 12/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4869 - accuracy: 0.7719 - auc: 0.8462\n","Epoch 13/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4783 - accuracy: 0.7780 - auc: 0.8531\n","Epoch 14/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4707 - accuracy: 0.7804 - auc: 0.8582\n","Epoch 15/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4696 - accuracy: 0.7838 - auc: 0.8596\n","Epoch 16/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4627 - accuracy: 0.7875 - auc: 0.8639\n","Epoch 17/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4517 - accuracy: 0.7881 - auc: 0.8705\n","Epoch 18/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4529 - accuracy: 0.7952 - auc: 0.8703\n","Epoch 19/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4525 - accuracy: 0.7939 - auc: 0.8703\n","Epoch 20/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4473 - accuracy: 0.7964 - auc: 0.8743\n","Epoch 21/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4479 - accuracy: 0.7954 - auc: 0.8729\n","Epoch 22/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4414 - accuracy: 0.8002 - auc: 0.8772\n","Epoch 23/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4335 - accuracy: 0.8071 - auc: 0.8816\n","Epoch 24/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4323 - accuracy: 0.8046 - auc: 0.8826\n","Epoch 25/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4231 - accuracy: 0.8071 - auc: 0.8882\n","Epoch 26/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4226 - accuracy: 0.8040 - auc: 0.8878\n","Epoch 27/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4198 - accuracy: 0.8109 - auc: 0.8899\n","Epoch 28/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4142 - accuracy: 0.8113 - auc: 0.8924\n","Epoch 29/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4121 - accuracy: 0.8196 - auc: 0.8938\n","Epoch 30/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4086 - accuracy: 0.8176 - auc: 0.8955\n","Epoch 31/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4105 - accuracy: 0.8230 - auc: 0.8958\n","Epoch 32/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3994 - accuracy: 0.8238 - auc: 0.9004\n","Epoch 33/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3986 - accuracy: 0.8271 - auc: 0.9018\n","Epoch 34/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3974 - accuracy: 0.8275 - auc: 0.9024\n","Epoch 35/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3906 - accuracy: 0.8297 - auc: 0.9056\n","Epoch 36/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3890 - accuracy: 0.8297 - auc: 0.9064\n","Epoch 37/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3908 - accuracy: 0.8287 - auc: 0.9050\n","Epoch 38/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3843 - accuracy: 0.8325 - auc: 0.9087\n","Epoch 39/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3812 - accuracy: 0.8297 - auc: 0.9099\n","Epoch 40/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3745 - accuracy: 0.8317 - auc: 0.9132\n","Epoch 41/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3765 - accuracy: 0.8311 - auc: 0.9121\n","Epoch 42/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3723 - accuracy: 0.8347 - auc: 0.9145\n","Epoch 43/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3774 - accuracy: 0.8358 - auc: 0.9117\n","Epoch 44/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3628 - accuracy: 0.8451 - auc: 0.9192\n","Epoch 45/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3614 - accuracy: 0.8424 - auc: 0.9197\n","Epoch 46/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3550 - accuracy: 0.8453 - auc: 0.9222\n","Epoch 47/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3528 - accuracy: 0.8444 - auc: 0.9236\n","Epoch 48/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3476 - accuracy: 0.8495 - auc: 0.9259\n","Epoch 49/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3511 - accuracy: 0.8434 - auc: 0.9237\n","Epoch 50/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3411 - accuracy: 0.8507 - auc: 0.9291\n","18/18 [==============================] - 2s 14ms/step - loss: 0.5000 - accuracy: 0.7818 - auc: 0.8526\n","18/18 [==============================] - 2s 13ms/step\n","0.7818181818181819 0.5636863601197508 0.8028673835125448 0.7601476014760148\n","[[206  65]\n"," [ 55 224]]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-72-07de00e87821>:31: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  y_pred = [int(i) for i in y_pred]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","310/310 [==============================] - 19s 32ms/step - loss: 0.6393 - accuracy: 0.6354 - auc: 0.6912\n","Epoch 2/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5798 - accuracy: 0.7059 - auc: 0.7675\n","Epoch 3/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5676 - accuracy: 0.7202 - auc: 0.7809\n","Epoch 4/50\n","310/310 [==============================] - 10s 31ms/step - loss: 0.5596 - accuracy: 0.7232 - auc: 0.7877\n","Epoch 5/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5537 - accuracy: 0.7214 - auc: 0.7927\n","Epoch 6/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5440 - accuracy: 0.7295 - auc: 0.8024\n","Epoch 7/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5371 - accuracy: 0.7428 - auc: 0.8073\n","Epoch 8/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5361 - accuracy: 0.7402 - auc: 0.8080\n","Epoch 9/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5232 - accuracy: 0.7471 - auc: 0.8189\n","Epoch 10/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5157 - accuracy: 0.7541 - auc: 0.8242\n","Epoch 11/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5040 - accuracy: 0.7598 - auc: 0.8341\n","Epoch 12/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4931 - accuracy: 0.7648 - auc: 0.8432\n","Epoch 13/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4885 - accuracy: 0.7703 - auc: 0.8451\n","Epoch 14/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4810 - accuracy: 0.7743 - auc: 0.8512\n","Epoch 15/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4728 - accuracy: 0.7802 - auc: 0.8563\n","Epoch 16/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4689 - accuracy: 0.7806 - auc: 0.8585\n","Epoch 17/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4668 - accuracy: 0.7905 - auc: 0.8602\n","Epoch 18/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4625 - accuracy: 0.7869 - auc: 0.8643\n","Epoch 19/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4580 - accuracy: 0.7875 - auc: 0.8661\n","Epoch 20/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4506 - accuracy: 0.7990 - auc: 0.8705\n","Epoch 21/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4473 - accuracy: 0.8002 - auc: 0.8731\n","Epoch 22/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4441 - accuracy: 0.8034 - auc: 0.8749\n","Epoch 23/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4430 - accuracy: 0.7992 - auc: 0.8759\n","Epoch 24/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4378 - accuracy: 0.8008 - auc: 0.8792\n","Epoch 25/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4354 - accuracy: 0.8032 - auc: 0.8809\n","Epoch 26/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4275 - accuracy: 0.8083 - auc: 0.8857\n","Epoch 27/50\n","310/310 [==============================] - 10s 31ms/step - loss: 0.4259 - accuracy: 0.8145 - auc: 0.8859\n","Epoch 28/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4217 - accuracy: 0.8141 - auc: 0.8885\n","Epoch 29/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4199 - accuracy: 0.8113 - auc: 0.8894\n","Epoch 30/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4154 - accuracy: 0.8180 - auc: 0.8930\n","Epoch 31/50\n","310/310 [==============================] - 10s 31ms/step - loss: 0.4145 - accuracy: 0.8164 - auc: 0.8928\n","Epoch 32/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4097 - accuracy: 0.8234 - auc: 0.8965\n","Epoch 33/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4110 - accuracy: 0.8186 - auc: 0.8945\n","Epoch 34/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3996 - accuracy: 0.8232 - auc: 0.8997\n","Epoch 35/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3993 - accuracy: 0.8248 - auc: 0.9011\n","Epoch 36/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3978 - accuracy: 0.8277 - auc: 0.9023\n","Epoch 37/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3947 - accuracy: 0.8293 - auc: 0.9032\n","Epoch 38/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3946 - accuracy: 0.8265 - auc: 0.9028\n","Epoch 39/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3864 - accuracy: 0.8323 - auc: 0.9083\n","Epoch 40/50\n","310/310 [==============================] - 10s 34ms/step - loss: 0.3803 - accuracy: 0.8426 - auc: 0.9117\n","Epoch 41/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3838 - accuracy: 0.8362 - auc: 0.9089\n","Epoch 42/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3782 - accuracy: 0.8388 - auc: 0.9112\n","Epoch 43/50\n","310/310 [==============================] - 10s 31ms/step - loss: 0.3699 - accuracy: 0.8416 - auc: 0.9159\n","Epoch 44/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3693 - accuracy: 0.8428 - auc: 0.9165\n","Epoch 45/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3661 - accuracy: 0.8428 - auc: 0.9173\n","Epoch 46/50\n","310/310 [==============================] - 11s 34ms/step - loss: 0.3608 - accuracy: 0.8424 - auc: 0.9196\n","Epoch 47/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3540 - accuracy: 0.8505 - auc: 0.9233\n","Epoch 48/50\n","310/310 [==============================] - 11s 34ms/step - loss: 0.3646 - accuracy: 0.8426 - auc: 0.9186\n","Epoch 49/50\n","310/310 [==============================] - 11s 34ms/step - loss: 0.3485 - accuracy: 0.8537 - auc: 0.9263\n","Epoch 50/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3490 - accuracy: 0.8507 - auc: 0.9253\n","18/18 [==============================] - 2s 14ms/step - loss: 0.4122 - accuracy: 0.8273 - auc: 0.8945\n","18/18 [==============================] - 2s 13ms/step\n","0.8272727272727273 0.6561265386813566 0.8028169014084507 0.8533834586466166\n","[[227  39]\n"," [ 56 228]]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-72-07de00e87821>:31: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  y_pred = [int(i) for i in y_pred]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","310/310 [==============================] - 17s 32ms/step - loss: 0.6274 - accuracy: 0.6564 - auc: 0.7151\n","Epoch 2/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5736 - accuracy: 0.7119 - auc: 0.7745\n","Epoch 3/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5614 - accuracy: 0.7244 - auc: 0.7861\n","Epoch 4/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5540 - accuracy: 0.7319 - auc: 0.7928\n","Epoch 5/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5470 - accuracy: 0.7329 - auc: 0.8003\n","Epoch 6/50\n","310/310 [==============================] - 10s 34ms/step - loss: 0.5384 - accuracy: 0.7398 - auc: 0.8075\n","Epoch 7/50\n","310/310 [==============================] - 11s 36ms/step - loss: 0.5306 - accuracy: 0.7455 - auc: 0.8131\n","Epoch 8/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5239 - accuracy: 0.7509 - auc: 0.8195\n","Epoch 9/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5141 - accuracy: 0.7525 - auc: 0.8272\n","Epoch 10/50\n","310/310 [==============================] - 10s 31ms/step - loss: 0.5013 - accuracy: 0.7608 - auc: 0.8368\n","Epoch 11/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4948 - accuracy: 0.7729 - auc: 0.8415\n","Epoch 12/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4859 - accuracy: 0.7749 - auc: 0.8470\n","Epoch 13/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4798 - accuracy: 0.7737 - auc: 0.8511\n","Epoch 14/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4776 - accuracy: 0.7776 - auc: 0.8532\n","Epoch 15/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4691 - accuracy: 0.7861 - auc: 0.8595\n","Epoch 16/50\n","310/310 [==============================] - 10s 34ms/step - loss: 0.4690 - accuracy: 0.7830 - auc: 0.8596\n","Epoch 17/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4601 - accuracy: 0.7905 - auc: 0.8649\n","Epoch 18/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4583 - accuracy: 0.7917 - auc: 0.8664\n","Epoch 19/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4500 - accuracy: 0.7941 - auc: 0.8719\n","Epoch 20/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4471 - accuracy: 0.7998 - auc: 0.8737\n","Epoch 21/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4471 - accuracy: 0.7974 - auc: 0.8726\n","Epoch 22/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4415 - accuracy: 0.7992 - auc: 0.8763\n","Epoch 23/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4336 - accuracy: 0.8063 - auc: 0.8823\n","Epoch 24/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4353 - accuracy: 0.8069 - auc: 0.8823\n","Epoch 25/50\n","310/310 [==============================] - 11s 36ms/step - loss: 0.4254 - accuracy: 0.8051 - auc: 0.8863\n","Epoch 26/50\n","310/310 [==============================] - 12s 37ms/step - loss: 0.4267 - accuracy: 0.8069 - auc: 0.8855\n","Epoch 27/50\n","310/310 [==============================] - 11s 36ms/step - loss: 0.4174 - accuracy: 0.8156 - auc: 0.8911\n","Epoch 28/50\n","310/310 [==============================] - 11s 35ms/step - loss: 0.4173 - accuracy: 0.8164 - auc: 0.8908\n","Epoch 29/50\n","310/310 [==============================] - 11s 35ms/step - loss: 0.4131 - accuracy: 0.8135 - auc: 0.8937\n","Epoch 30/50\n","310/310 [==============================] - 11s 36ms/step - loss: 0.4109 - accuracy: 0.8194 - auc: 0.8946\n","Epoch 31/50\n","310/310 [==============================] - 10s 31ms/step - loss: 0.4105 - accuracy: 0.8202 - auc: 0.8954\n","Epoch 32/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4044 - accuracy: 0.8168 - auc: 0.8978\n","Epoch 33/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4094 - accuracy: 0.8141 - auc: 0.8953\n","Epoch 34/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4012 - accuracy: 0.8210 - auc: 0.8999\n","Epoch 35/50\n","310/310 [==============================] - 10s 31ms/step - loss: 0.3950 - accuracy: 0.8291 - auc: 0.9042\n","Epoch 36/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3941 - accuracy: 0.8253 - auc: 0.9037\n","Epoch 37/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3874 - accuracy: 0.8317 - auc: 0.9070\n","Epoch 38/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3850 - accuracy: 0.8364 - auc: 0.9091\n","Epoch 39/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3860 - accuracy: 0.8323 - auc: 0.9079\n","Epoch 40/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3802 - accuracy: 0.8345 - auc: 0.9110\n","Epoch 41/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3759 - accuracy: 0.8394 - auc: 0.9134\n","Epoch 42/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3749 - accuracy: 0.8360 - auc: 0.9133\n","Epoch 43/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3709 - accuracy: 0.8386 - auc: 0.9151\n","Epoch 44/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3674 - accuracy: 0.8430 - auc: 0.9171\n","Epoch 45/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3621 - accuracy: 0.8457 - auc: 0.9202\n","Epoch 46/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3570 - accuracy: 0.8475 - auc: 0.9219\n","Epoch 47/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3538 - accuracy: 0.8446 - auc: 0.9232\n","Epoch 48/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3519 - accuracy: 0.8467 - auc: 0.9238\n","Epoch 49/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3507 - accuracy: 0.8479 - auc: 0.9248\n","Epoch 50/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3450 - accuracy: 0.8558 - auc: 0.9274\n","18/18 [==============================] - 2s 14ms/step - loss: 0.4633 - accuracy: 0.7945 - auc: 0.8710\n","18/18 [==============================] - 2s 14ms/step\n","0.7945454545454546 0.5928212140371344 0.7535211267605634 0.8383458646616542\n","[[223  43]\n"," [ 70 214]]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-72-07de00e87821>:31: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  y_pred = [int(i) for i in y_pred]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","310/310 [==============================] - 17s 32ms/step - loss: 0.6345 - accuracy: 0.6463 - auc: 0.7046\n","Epoch 2/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5794 - accuracy: 0.7069 - auc: 0.7678\n","Epoch 3/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5666 - accuracy: 0.7196 - auc: 0.7802\n","Epoch 4/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5596 - accuracy: 0.7279 - auc: 0.7891\n","Epoch 5/50\n","310/310 [==============================] - 10s 34ms/step - loss: 0.5535 - accuracy: 0.7345 - auc: 0.7939\n","Epoch 6/50\n","310/310 [==============================] - 11s 36ms/step - loss: 0.5450 - accuracy: 0.7327 - auc: 0.8015\n","Epoch 7/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5352 - accuracy: 0.7408 - auc: 0.8091\n","Epoch 8/50\n","310/310 [==============================] - 10s 31ms/step - loss: 0.5281 - accuracy: 0.7473 - auc: 0.8152\n","Epoch 9/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5209 - accuracy: 0.7515 - auc: 0.8216\n","Epoch 10/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5081 - accuracy: 0.7560 - auc: 0.8311\n","Epoch 11/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5061 - accuracy: 0.7584 - auc: 0.8329\n","Epoch 12/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4935 - accuracy: 0.7733 - auc: 0.8439\n","Epoch 13/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4876 - accuracy: 0.7743 - auc: 0.8475\n","Epoch 14/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4794 - accuracy: 0.7806 - auc: 0.8526\n","Epoch 15/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4738 - accuracy: 0.7814 - auc: 0.8562\n","Epoch 16/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4680 - accuracy: 0.7875 - auc: 0.8605\n","Epoch 17/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4630 - accuracy: 0.7842 - auc: 0.8637\n","Epoch 18/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4574 - accuracy: 0.7952 - auc: 0.8678\n","Epoch 19/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4567 - accuracy: 0.7883 - auc: 0.8671\n","Epoch 20/50\n","310/310 [==============================] - 10s 31ms/step - loss: 0.4516 - accuracy: 0.7954 - auc: 0.8707\n","Epoch 21/50\n","310/310 [==============================] - 10s 31ms/step - loss: 0.4494 - accuracy: 0.7974 - auc: 0.8725\n","Epoch 22/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4479 - accuracy: 0.8020 - auc: 0.8744\n","Epoch 23/50\n","310/310 [==============================] - 10s 31ms/step - loss: 0.4374 - accuracy: 0.8038 - auc: 0.8794\n","Epoch 24/50\n","310/310 [==============================] - 10s 31ms/step - loss: 0.4346 - accuracy: 0.8002 - auc: 0.8812\n","Epoch 25/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4310 - accuracy: 0.8071 - auc: 0.8829\n","Epoch 26/50\n","310/310 [==============================] - 10s 31ms/step - loss: 0.4326 - accuracy: 0.8063 - auc: 0.8815\n","Epoch 27/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4266 - accuracy: 0.8101 - auc: 0.8858\n","Epoch 28/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4264 - accuracy: 0.8139 - auc: 0.8868\n","Epoch 29/50\n","310/310 [==============================] - 10s 31ms/step - loss: 0.4175 - accuracy: 0.8180 - auc: 0.8918\n","Epoch 30/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4174 - accuracy: 0.8103 - auc: 0.8914\n","Epoch 31/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4157 - accuracy: 0.8143 - auc: 0.8918\n","Epoch 32/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4089 - accuracy: 0.8188 - auc: 0.8962\n","Epoch 33/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4045 - accuracy: 0.8263 - auc: 0.8989\n","Epoch 34/50\n","310/310 [==============================] - 10s 31ms/step - loss: 0.4104 - accuracy: 0.8232 - auc: 0.8949\n","Epoch 35/50\n","310/310 [==============================] - 10s 31ms/step - loss: 0.4039 - accuracy: 0.8186 - auc: 0.8980\n","Epoch 36/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3973 - accuracy: 0.8222 - auc: 0.9015\n","Epoch 37/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3959 - accuracy: 0.8273 - auc: 0.9025\n","Epoch 38/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3918 - accuracy: 0.8297 - auc: 0.9043\n","Epoch 39/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3784 - accuracy: 0.8362 - auc: 0.9116\n","Epoch 40/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3861 - accuracy: 0.8352 - auc: 0.9072\n","Epoch 41/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3837 - accuracy: 0.8311 - auc: 0.9092\n","Epoch 42/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3813 - accuracy: 0.8354 - auc: 0.9103\n","Epoch 43/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3755 - accuracy: 0.8356 - auc: 0.9134\n","Epoch 44/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3797 - accuracy: 0.8341 - auc: 0.9113\n","Epoch 45/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3704 - accuracy: 0.8434 - auc: 0.9153\n","Epoch 46/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3770 - accuracy: 0.8368 - auc: 0.9127\n","Epoch 47/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3627 - accuracy: 0.8459 - auc: 0.9199\n","Epoch 48/50\n","310/310 [==============================] - 10s 34ms/step - loss: 0.3601 - accuracy: 0.8465 - auc: 0.9205\n","Epoch 49/50\n","310/310 [==============================] - 10s 34ms/step - loss: 0.3559 - accuracy: 0.8467 - auc: 0.9221\n","Epoch 50/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3519 - accuracy: 0.8509 - auc: 0.9240\n","18/18 [==============================] - 2s 15ms/step - loss: 0.4246 - accuracy: 0.8127 - auc: 0.8874\n","18/18 [==============================] - 2s 14ms/step\n","0.8127272727272727 0.625955510328977 0.7927272727272727 0.8327272727272728\n","[[229  46]\n"," [ 57 218]]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-72-07de00e87821>:31: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  y_pred = [int(i) for i in y_pred]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","310/310 [==============================] - 20s 34ms/step - loss: 0.6327 - accuracy: 0.6416 - auc: 0.6999\n","Epoch 2/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5760 - accuracy: 0.7051 - auc: 0.7721\n","Epoch 3/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5640 - accuracy: 0.7240 - auc: 0.7837\n","Epoch 4/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5585 - accuracy: 0.7251 - auc: 0.7886\n","Epoch 5/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5537 - accuracy: 0.7333 - auc: 0.7926\n","Epoch 6/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5459 - accuracy: 0.7364 - auc: 0.8005\n","Epoch 7/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5379 - accuracy: 0.7396 - auc: 0.8077\n","Epoch 8/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5282 - accuracy: 0.7406 - auc: 0.8149\n","Epoch 9/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5240 - accuracy: 0.7499 - auc: 0.8193\n","Epoch 10/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5124 - accuracy: 0.7560 - auc: 0.8276\n","Epoch 11/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5052 - accuracy: 0.7570 - auc: 0.8322\n","Epoch 12/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4995 - accuracy: 0.7665 - auc: 0.8378\n","Epoch 13/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4932 - accuracy: 0.7661 - auc: 0.8419\n","Epoch 14/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4837 - accuracy: 0.7764 - auc: 0.8486\n","Epoch 15/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4813 - accuracy: 0.7749 - auc: 0.8502\n","Epoch 16/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4720 - accuracy: 0.7834 - auc: 0.8575\n","Epoch 17/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4671 - accuracy: 0.7832 - auc: 0.8597\n","Epoch 18/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4642 - accuracy: 0.7887 - auc: 0.8625\n","Epoch 19/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4587 - accuracy: 0.7869 - auc: 0.8659\n","Epoch 20/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4550 - accuracy: 0.7877 - auc: 0.8683\n","Epoch 21/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4472 - accuracy: 0.7949 - auc: 0.8734\n","Epoch 22/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4424 - accuracy: 0.7954 - auc: 0.8763\n","Epoch 23/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4412 - accuracy: 0.7980 - auc: 0.8775\n","Epoch 24/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4326 - accuracy: 0.8057 - auc: 0.8821\n","Epoch 25/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4316 - accuracy: 0.8016 - auc: 0.8820\n","Epoch 26/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4313 - accuracy: 0.7984 - auc: 0.8829\n","Epoch 27/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4231 - accuracy: 0.8101 - auc: 0.8876\n","Epoch 28/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4196 - accuracy: 0.8040 - auc: 0.8882\n","Epoch 29/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4145 - accuracy: 0.8117 - auc: 0.8927\n","Epoch 30/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4133 - accuracy: 0.8071 - auc: 0.8925\n","Epoch 31/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4120 - accuracy: 0.8184 - auc: 0.8945\n","Epoch 32/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4079 - accuracy: 0.8156 - auc: 0.8964\n","Epoch 33/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4054 - accuracy: 0.8147 - auc: 0.8972\n","Epoch 34/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4002 - accuracy: 0.8253 - auc: 0.9005\n","Epoch 35/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3995 - accuracy: 0.8224 - auc: 0.9009\n","Epoch 36/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3948 - accuracy: 0.8263 - auc: 0.9033\n","Epoch 37/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3908 - accuracy: 0.8257 - auc: 0.9045\n","Epoch 38/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3891 - accuracy: 0.8279 - auc: 0.9058\n","Epoch 39/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3877 - accuracy: 0.8240 - auc: 0.9061\n","Epoch 40/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3838 - accuracy: 0.8238 - auc: 0.9085\n","Epoch 41/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3784 - accuracy: 0.8325 - auc: 0.9115\n","Epoch 42/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3716 - accuracy: 0.8331 - auc: 0.9152\n","Epoch 43/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3735 - accuracy: 0.8392 - auc: 0.9136\n","Epoch 44/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3676 - accuracy: 0.8392 - auc: 0.9164\n","Epoch 45/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3639 - accuracy: 0.8390 - auc: 0.9183\n","Epoch 46/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3676 - accuracy: 0.8438 - auc: 0.9165\n","Epoch 47/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3556 - accuracy: 0.8402 - auc: 0.9224\n","Epoch 48/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3539 - accuracy: 0.8463 - auc: 0.9230\n","Epoch 49/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3553 - accuracy: 0.8467 - auc: 0.9225\n","Epoch 50/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3445 - accuracy: 0.8475 - auc: 0.9275\n","18/18 [==============================] - 2s 13ms/step - loss: 0.4230 - accuracy: 0.8145 - auc: 0.8922\n","18/18 [==============================] - 2s 13ms/step\n","0.8145454545454546 0.6295553500335966 0.7859778597785978 0.8422939068100358\n","[[235  44]\n"," [ 58 213]]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-72-07de00e87821>:31: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  y_pred = [int(i) for i in y_pred]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","310/310 [==============================] - 17s 32ms/step - loss: 0.6330 - accuracy: 0.6461 - auc: 0.7030\n","Epoch 2/50\n","310/310 [==============================] - 10s 31ms/step - loss: 0.5723 - accuracy: 0.7198 - auc: 0.7751\n","Epoch 3/50\n","310/310 [==============================] - 10s 31ms/step - loss: 0.5617 - accuracy: 0.7273 - auc: 0.7861\n","Epoch 4/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5483 - accuracy: 0.7374 - auc: 0.7984\n","Epoch 5/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5439 - accuracy: 0.7360 - auc: 0.8034\n","Epoch 6/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5356 - accuracy: 0.7440 - auc: 0.8111\n","Epoch 7/50\n","310/310 [==============================] - 10s 31ms/step - loss: 0.5266 - accuracy: 0.7527 - auc: 0.8175\n","Epoch 8/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5179 - accuracy: 0.7533 - auc: 0.8234\n","Epoch 9/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.5069 - accuracy: 0.7646 - auc: 0.8338\n","Epoch 10/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4969 - accuracy: 0.7669 - auc: 0.8408\n","Epoch 11/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4917 - accuracy: 0.7689 - auc: 0.8440\n","Epoch 12/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4818 - accuracy: 0.7770 - auc: 0.8504\n","Epoch 13/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4757 - accuracy: 0.7812 - auc: 0.8560\n","Epoch 14/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4737 - accuracy: 0.7855 - auc: 0.8564\n","Epoch 15/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4636 - accuracy: 0.7846 - auc: 0.8635\n","Epoch 16/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4582 - accuracy: 0.7921 - auc: 0.8665\n","Epoch 17/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4577 - accuracy: 0.7917 - auc: 0.8663\n","Epoch 18/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4499 - accuracy: 0.7925 - auc: 0.8720\n","Epoch 19/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4448 - accuracy: 0.8002 - auc: 0.8753\n","Epoch 20/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4380 - accuracy: 0.8000 - auc: 0.8793\n","Epoch 21/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4371 - accuracy: 0.8046 - auc: 0.8801\n","Epoch 22/50\n","310/310 [==============================] - 10s 31ms/step - loss: 0.4352 - accuracy: 0.8071 - auc: 0.8811\n","Epoch 23/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4253 - accuracy: 0.8089 - auc: 0.8868\n","Epoch 24/50\n","310/310 [==============================] - 10s 31ms/step - loss: 0.4251 - accuracy: 0.8048 - auc: 0.8869\n","Epoch 25/50\n","310/310 [==============================] - 10s 31ms/step - loss: 0.4231 - accuracy: 0.8107 - auc: 0.8885\n","Epoch 26/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4186 - accuracy: 0.8164 - auc: 0.8911\n","Epoch 27/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4173 - accuracy: 0.8182 - auc: 0.8909\n","Epoch 28/50\n","310/310 [==============================] - 11s 34ms/step - loss: 0.4124 - accuracy: 0.8186 - auc: 0.8944\n","Epoch 29/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4099 - accuracy: 0.8149 - auc: 0.8953\n","Epoch 30/50\n","310/310 [==============================] - 11s 34ms/step - loss: 0.4048 - accuracy: 0.8158 - auc: 0.8984\n","Epoch 31/50\n","310/310 [==============================] - 11s 35ms/step - loss: 0.3993 - accuracy: 0.8182 - auc: 0.9005\n","Epoch 32/50\n","310/310 [==============================] - 11s 36ms/step - loss: 0.3960 - accuracy: 0.8263 - auc: 0.9033\n","Epoch 33/50\n","310/310 [==============================] - 11s 37ms/step - loss: 0.3926 - accuracy: 0.8281 - auc: 0.9042\n","Epoch 34/50\n","310/310 [==============================] - 11s 35ms/step - loss: 0.3946 - accuracy: 0.8297 - auc: 0.9030\n","Epoch 35/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3892 - accuracy: 0.8293 - auc: 0.9061\n","Epoch 36/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3850 - accuracy: 0.8352 - auc: 0.9086\n","Epoch 37/50\n","310/310 [==============================] - 11s 35ms/step - loss: 0.3836 - accuracy: 0.8356 - auc: 0.9093\n","Epoch 38/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3826 - accuracy: 0.8335 - auc: 0.9093\n","Epoch 39/50\n","310/310 [==============================] - 10s 31ms/step - loss: 0.3743 - accuracy: 0.8386 - auc: 0.9133\n","Epoch 40/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3748 - accuracy: 0.8323 - auc: 0.9136\n","Epoch 41/50\n","310/310 [==============================] - 11s 36ms/step - loss: 0.3703 - accuracy: 0.8426 - auc: 0.9157\n","Epoch 42/50\n","310/310 [==============================] - 11s 35ms/step - loss: 0.3692 - accuracy: 0.8388 - auc: 0.9157\n","Epoch 43/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3659 - accuracy: 0.8376 - auc: 0.9171\n","Epoch 44/50\n","310/310 [==============================] - 11s 34ms/step - loss: 0.3620 - accuracy: 0.8440 - auc: 0.9195\n","Epoch 45/50\n","310/310 [==============================] - 10s 34ms/step - loss: 0.3574 - accuracy: 0.8400 - auc: 0.9214\n","Epoch 46/50\n","310/310 [==============================] - 11s 35ms/step - loss: 0.3551 - accuracy: 0.8453 - auc: 0.9228\n","Epoch 47/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.3504 - accuracy: 0.8451 - auc: 0.9246\n","Epoch 48/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3448 - accuracy: 0.8523 - auc: 0.9273\n","Epoch 49/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3466 - accuracy: 0.8527 - auc: 0.9265\n","Epoch 50/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3440 - accuracy: 0.8481 - auc: 0.9277\n","18/18 [==============================] - 2s 14ms/step - loss: 0.5168 - accuracy: 0.7582 - auc: 0.8457\n","18/18 [==============================] - 2s 13ms/step\n","0.7581818181818182 0.5253498775308103 0.6714801444043321 0.8461538461538461\n","[[231  42]\n"," [ 91 186]]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-72-07de00e87821>:31: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  y_pred = [int(i) for i in y_pred]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","310/310 [==============================] - 20s 34ms/step - loss: 0.6351 - accuracy: 0.6390 - auc: 0.6982\n","Epoch 2/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.5754 - accuracy: 0.7129 - auc: 0.7729\n","Epoch 3/50\n","310/310 [==============================] - 12s 39ms/step - loss: 0.5631 - accuracy: 0.7242 - auc: 0.7859\n","Epoch 4/50\n","310/310 [==============================] - 11s 34ms/step - loss: 0.5538 - accuracy: 0.7281 - auc: 0.7946\n","Epoch 5/50\n","310/310 [==============================] - 11s 34ms/step - loss: 0.5438 - accuracy: 0.7392 - auc: 0.8025\n","Epoch 6/50\n","310/310 [==============================] - 11s 36ms/step - loss: 0.5371 - accuracy: 0.7356 - auc: 0.8078\n","Epoch 7/50\n","310/310 [==============================] - 12s 38ms/step - loss: 0.5305 - accuracy: 0.7463 - auc: 0.8140\n","Epoch 8/50\n","310/310 [==============================] - 12s 39ms/step - loss: 0.5228 - accuracy: 0.7475 - auc: 0.8210\n","Epoch 9/50\n","310/310 [==============================] - 11s 34ms/step - loss: 0.5140 - accuracy: 0.7572 - auc: 0.8273\n","Epoch 10/50\n","310/310 [==============================] - 11s 34ms/step - loss: 0.5038 - accuracy: 0.7628 - auc: 0.8356\n","Epoch 11/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4908 - accuracy: 0.7699 - auc: 0.8445\n","Epoch 12/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4877 - accuracy: 0.7741 - auc: 0.8459\n","Epoch 13/50\n","310/310 [==============================] - 10s 34ms/step - loss: 0.4805 - accuracy: 0.7749 - auc: 0.8513\n","Epoch 14/50\n","310/310 [==============================] - 11s 34ms/step - loss: 0.4717 - accuracy: 0.7786 - auc: 0.8577\n","Epoch 15/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4689 - accuracy: 0.7842 - auc: 0.8587\n","Epoch 16/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4618 - accuracy: 0.7836 - auc: 0.8636\n","Epoch 17/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4580 - accuracy: 0.7885 - auc: 0.8673\n","Epoch 18/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4507 - accuracy: 0.7853 - auc: 0.8706\n","Epoch 19/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4503 - accuracy: 0.7943 - auc: 0.8713\n","Epoch 20/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4473 - accuracy: 0.7960 - auc: 0.8744\n","Epoch 21/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4396 - accuracy: 0.8044 - auc: 0.8782\n","Epoch 22/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4388 - accuracy: 0.7984 - auc: 0.8791\n","Epoch 23/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4352 - accuracy: 0.8046 - auc: 0.8814\n","Epoch 24/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4272 - accuracy: 0.8063 - auc: 0.8852\n","Epoch 25/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4181 - accuracy: 0.8164 - auc: 0.8916\n","Epoch 26/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4161 - accuracy: 0.8135 - auc: 0.8919\n","Epoch 27/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4164 - accuracy: 0.8121 - auc: 0.8919\n","Epoch 28/50\n","310/310 [==============================] - 10s 32ms/step - loss: 0.4108 - accuracy: 0.8143 - auc: 0.8946\n","Epoch 29/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4126 - accuracy: 0.8200 - auc: 0.8941\n","Epoch 30/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4053 - accuracy: 0.8184 - auc: 0.8979\n","Epoch 31/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.4057 - accuracy: 0.8228 - auc: 0.8972\n","Epoch 32/50\n","310/310 [==============================] - 10s 34ms/step - loss: 0.4019 - accuracy: 0.8222 - auc: 0.8996\n","Epoch 33/50\n","310/310 [==============================] - 11s 34ms/step - loss: 0.3950 - accuracy: 0.8283 - auc: 0.9035\n","Epoch 34/50\n","310/310 [==============================] - 11s 35ms/step - loss: 0.3905 - accuracy: 0.8301 - auc: 0.9052\n","Epoch 35/50\n","310/310 [==============================] - 11s 36ms/step - loss: 0.3877 - accuracy: 0.8313 - auc: 0.9077\n","Epoch 36/50\n","310/310 [==============================] - 11s 35ms/step - loss: 0.3842 - accuracy: 0.8283 - auc: 0.9084\n","Epoch 37/50\n","310/310 [==============================] - 11s 36ms/step - loss: 0.3861 - accuracy: 0.8303 - auc: 0.9076\n","Epoch 38/50\n","310/310 [==============================] - 11s 35ms/step - loss: 0.3852 - accuracy: 0.8275 - auc: 0.9085\n","Epoch 39/50\n","310/310 [==============================] - 11s 37ms/step - loss: 0.3823 - accuracy: 0.8283 - auc: 0.9099\n","Epoch 40/50\n","310/310 [==============================] - 11s 37ms/step - loss: 0.3730 - accuracy: 0.8394 - auc: 0.9148\n","Epoch 41/50\n","310/310 [==============================] - 11s 36ms/step - loss: 0.3715 - accuracy: 0.8360 - auc: 0.9149\n","Epoch 42/50\n","310/310 [==============================] - 11s 34ms/step - loss: 0.3709 - accuracy: 0.8430 - auc: 0.9150\n","Epoch 43/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3715 - accuracy: 0.8370 - auc: 0.9152\n","Epoch 44/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3698 - accuracy: 0.8402 - auc: 0.9159\n","Epoch 45/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3595 - accuracy: 0.8424 - auc: 0.9211\n","Epoch 46/50\n","310/310 [==============================] - 10s 34ms/step - loss: 0.3601 - accuracy: 0.8459 - auc: 0.9205\n","Epoch 47/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3602 - accuracy: 0.8394 - auc: 0.9199\n","Epoch 48/50\n","310/310 [==============================] - 10s 34ms/step - loss: 0.3489 - accuracy: 0.8539 - auc: 0.9263\n","Epoch 49/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3550 - accuracy: 0.8483 - auc: 0.9227\n","Epoch 50/50\n","310/310 [==============================] - 10s 33ms/step - loss: 0.3440 - accuracy: 0.8543 - auc: 0.9283\n","18/18 [==============================] - 2s 14ms/step - loss: 0.5081 - accuracy: 0.7855 - auc: 0.8516\n","18/18 [==============================] - 2s 14ms/step\n","0.7854545454545454 0.569649509937933 0.7993079584775087 0.7701149425287356\n","[[201  60]\n"," [ 58 231]]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-72-07de00e87821>:31: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  y_pred = [int(i) for i in y_pred]\n"]}],"source":["# Cross CNN_BiLSTM\n","num_folds =10\n","\n","kf = KFold(n_splits=num_folds, shuffle=True)\n","\n","X = Xtrain\n","y = ytrain\n","\n","for train_index, test_index in kf.split(X):# X1 physical feature, X2 NLP features\n","    X_train, X_test = X[train_index], X[test_index]\n","\n","    Y_train, Y_test = y[train_index], y[test_index]\n","    model = Classifier_hybrid()\n","    model.fit([X_train,X_train], Y_train, batch_size=16, epochs=num_epochs)\n","    result1 = model.evaluate([X_test,X_test],Y_test)\n","    f = open(result_hybrid, 'a+', encoding='UTF-8')\n","    f.write(\"\\n Crossvalidation test 5.7.2024\")\n","\n","    s = str(result1)\n","    f.write(s)\n","    f.close()\n","    # Define your model\n","    # Compile the model with the desired optimizer, loss function, and metrics\n","\n","    y_pred= model.predict([X_test,X_test])\n","    ytest_true = Y_test\n","    #y_pred = model.predict([Xtest,Xtest])\n","\n","    y_pred = (y_pred > 0.5)\n","\n","    y_pred = [int(i) for i in y_pred]\n","\n","    y_pred = np.array(y_pred)\n","    y_true = np.array(ytest_true)\n","\n","    cm = confusion_matrix(y_true, y_pred)\n","    mcc = matthews_corrcoef(y_true, y_pred)\n","    acc = accuracy_score(y_true, y_pred)\n","\n","    sn = cm[1][1]/(cm[1][1]+cm[1][0])\n","    sp = cm[0][0]/(cm[0][0]+cm[0][1])\n","    print(acc, mcc,sn,sp)\n","    print(cm)\n","\n","    f = open(result_hybrid, 'a+', encoding='UTF-8')\n","    f.write(\"\\n crossvalidation confusion_matric\\n \")\n","    s = str(cm)\n","    f.write(s)\n","    f.close()"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}